{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "from xml.dom.minidom import parse\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import random\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import models\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os\n",
    "import cv2\n",
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from torchvision.transforms import functional as F\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from pycocotools.mask import encode as encode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = os.listdir(r'dataset\\test')\n",
    "img_id = [2, 1, 4, 3, 5, 6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = torch.load('model.pt')\n",
    "device = torch.device(\n",
    "    'cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "answer = []\n",
    "\n",
    "for i in range(6):\n",
    "    for x in range(4):\n",
    "        for y in range(4):\n",
    "            img = Image.open('dataset/test/' + img_list[i])\n",
    "            xmin, ymin, xmax, ymax = 0+x*250, 0+y*250, 250+x*250, 250+y*250\n",
    "            # print(xmin,ymin,xmax,ymax)\n",
    "            img = img.crop((xmin, ymin, xmax, ymax))\n",
    "            img = transform(img)\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                prediction = model([img.to(device)])\n",
    "            for ii in range(min(prediction[0]['boxes'].cpu().shape[0], 2000)):\n",
    "\n",
    "                box_xmin = round(prediction[0]['boxes'][ii][0].item())\n",
    "                box_ymin = round(prediction[0]['boxes'][ii][1].item())\n",
    "                box_xmax = round(prediction[0]['boxes'][ii][2].item())\n",
    "                box_ymax = round(prediction[0]['boxes'][ii][3].item())\n",
    "\n",
    "                if (box_xmin == 0 and x != 0) or (box_xmax >= 249 and x != 3):\n",
    "                    continue\n",
    "                if (box_ymin == 0 and y != 0) or (box_ymax >= 249 and y != 3):\n",
    "                    continue\n",
    "\n",
    "                box_x, box_y, box_width, box_height = \\\n",
    "                    box_xmin, box_ymin, box_xmax - \\\n",
    "                    box_xmin, box_ymax-box_ymin\n",
    "\n",
    "                mask = prediction[0]['masks'][ii][0].cpu()\n",
    "                mask = np.array(mask)\n",
    "                mask = cv2.copyMakeBorder(\n",
    "                    mask, ymin-0, 1000-ymax, xmin-0,\n",
    "                    1000-xmax, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "                mask[np.where(mask > 0.7)] = 1\n",
    "                # print(mask.shape)\n",
    "                mask = np.asfortranarray(mask).astype(np.uint8)\n",
    "                mask_counts = (encode(np.asfortranarray(mask))\n",
    "                               ['counts']).decode('utf8')\n",
    "                # print(sqrt((xmax - xmin)*(ymax-ymin)))\n",
    "                label = prediction[0]['labels'][ii].item()\n",
    "                score = prediction[0]['scores'][ii].item()\n",
    "\n",
    "                dict = {}\n",
    "                dict['image_id'] = img_id[i]\n",
    "                dict['bbox'] = [box_x+xmin, box_y+ymin, box_width, box_height]\n",
    "                dict['score'] = float(score)\n",
    "                dict['category_id'] = 1\n",
    "                dict['segmentation'] = {\n",
    "                    \"size\": [1000, 1000], 'counts': mask_counts}\n",
    "                answer.append(dict)\n",
    "\n",
    "    for x in range(3):\n",
    "        for y in range(4):\n",
    "            img = Image.open('dataset/test/' + img_list[i])\n",
    "            xmin, ymin, xmax, ymax = 125+x*250, 0+y*250, 375+x*250, 250+y*250\n",
    "            # print(xmin,ymin,xmax,ymax)\n",
    "            img = img.crop((xmin, ymin, xmax, ymax))\n",
    "            img = transform(img)\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                prediction = model([img.to(device)])\n",
    "            for ii in range(min(prediction[0]['boxes'].cpu().shape[0], 2000)):\n",
    "\n",
    "                box_xmin = round(prediction[0]['boxes'][ii][0].item())\n",
    "                box_ymin = round(prediction[0]['boxes'][ii][1].item())\n",
    "                box_xmax = round(prediction[0]['boxes'][ii][2].item())\n",
    "                box_ymax = round(prediction[0]['boxes'][ii][3].item())\n",
    "                if (box_ymin == 0 and y != 0) or (box_ymax >= 249 and y != 3):\n",
    "                    continue\n",
    "                if(box_xmin < 125 and box_xmax > 125):\n",
    "                    pass\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                box_x, box_y, box_width, box_height = \\\n",
    "                    box_xmin, box_ymin, box_xmax - \\\n",
    "                    box_xmin, box_ymax-box_ymin\n",
    "\n",
    "                mask = prediction[0]['masks'][ii][0].cpu()\n",
    "                mask = np.array(mask)\n",
    "                mask = cv2.copyMakeBorder(\n",
    "                    mask, ymin-0, 1000-ymax, xmin-0, 1000-xmax,\n",
    "                    cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "                mask[np.where(mask > 0.7)] = 1\n",
    "                mask = np.asfortranarray(mask).astype(np.uint8)\n",
    "                mask_counts = (encode(np.asfortranarray(mask))\n",
    "                               ['counts']).decode('utf8')\n",
    "                # print(sqrt((xmax - xmin)*(ymax-ymin)))\n",
    "                label = prediction[0]['labels'][ii].item()\n",
    "                score = prediction[0]['scores'][ii].item()\n",
    "\n",
    "                dict = {}\n",
    "                dict['image_id'] = img_id[i]\n",
    "                dict['bbox'] = [box_x+xmin, box_y+ymin, box_width, box_height]\n",
    "                dict['score'] = float(score)\n",
    "                dict['category_id'] = 1\n",
    "                dict['segmentation'] = {\n",
    "                    \"size\": [1000, 1000], 'counts': mask_counts}\n",
    "                answer.append(dict)\n",
    "\n",
    "    for x in range(4):\n",
    "        for y in range(3):\n",
    "            img = Image.open('dataset/test/' + img_list[i])\n",
    "            xmin, ymin, xmax, ymax = 0+x*250, 125+y*250, 250+x*250, 375+y*250\n",
    "            # print(xmin,ymin,xmax,ymax)\n",
    "            img = img.crop((xmin, ymin, xmax, ymax))\n",
    "            img = transform(img)\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                prediction = model([img.to(device)])\n",
    "            for ii in range(min(prediction[0]['boxes'].cpu().shape[0], 2000)):\n",
    "\n",
    "                box_xmin = round(prediction[0]['boxes'][ii][0].item())\n",
    "                box_ymin = round(prediction[0]['boxes'][ii][1].item())\n",
    "                box_xmax = round(prediction[0]['boxes'][ii][2].item())\n",
    "                box_ymax = round(prediction[0]['boxes'][ii][3].item())\n",
    "                if (box_xmin == 0 and x != 0) or (box_xmax >= 249 and x != 3):\n",
    "                    continue\n",
    "                if(box_ymin < 125 and box_ymax > 125):\n",
    "                    pass\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                box_x, box_y, box_width, box_height = \\\n",
    "                    box_xmin, box_ymin, box_xmax - \\\n",
    "                    box_xmin, box_ymax-box_ymin\n",
    "\n",
    "                mask = prediction[0]['masks'][ii][0].cpu()\n",
    "                mask = np.array(mask)\n",
    "                mask = cv2.copyMakeBorder(\n",
    "                    mask, ymin-0, 1000-ymax,\n",
    "                    xmin-0, 1000-xmax, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "                mask[np.where(mask > 0.7)] = 1\n",
    "                mask = np.asfortranarray(mask).astype(np.uint8)\n",
    "                mask_counts = (encode(np.asfortranarray(mask))\n",
    "                               ['counts']).decode('utf8')\n",
    "                # print(sqrt((xmax - xmin)*(ymax-ymin)))\n",
    "                label = prediction[0]['labels'][ii].item()\n",
    "                score = prediction[0]['scores'][ii].item()\n",
    "\n",
    "                dict = {}\n",
    "                dict['image_id'] = img_id[i]\n",
    "                dict['bbox'] = [box_x+xmin, box_y+ymin, box_width, box_height]\n",
    "                dict['score'] = float(score)\n",
    "                dict['category_id'] = 1\n",
    "                dict['segmentation'] = {\n",
    "                    \"size\": [1000, 1000], 'counts': mask_counts}\n",
    "                answer.append(dict)\n",
    "\n",
    "    for x in range(3):\n",
    "        for y in range(3):\n",
    "            img = Image.open('dataset/test/' + img_list[i])\n",
    "            xmin, ymin, xmax, ymax = 125+x*250, 125+y*250, 375+x*250, 375+y*250\n",
    "            img = img.crop((xmin, ymin, xmax, ymax))\n",
    "            img = transform(img)\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                prediction = model([img.to(device)])\n",
    "            for ii in range(min(prediction[0]['boxes'].cpu().shape[0], 2000)):\n",
    "\n",
    "                box_xmin = round(prediction[0]['boxes'][ii][0].item())\n",
    "                box_ymin = round(prediction[0]['boxes'][ii][1].item())\n",
    "                box_xmax = round(prediction[0]['boxes'][ii][2].item())\n",
    "                box_ymax = round(prediction[0]['boxes'][ii][3].item())\n",
    "                if(box_xmin < 125 and box_xmax > 125):\n",
    "                    pass\n",
    "                else:\n",
    "                    continue\n",
    "                if(box_ymin < 125 and box_ymax > 125):\n",
    "                    pass\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                box_x, box_y, box_width, box_height = \\\n",
    "                    box_xmin, box_ymin, box_xmax - \\\n",
    "                    box_xmin, box_ymax-box_ymin\n",
    "\n",
    "                mask = prediction[0]['masks'][ii][0].cpu()\n",
    "                mask = np.array(mask)\n",
    "                mask = cv2.copyMakeBorder(\n",
    "                    mask, ymin-0, 1000-ymax, xmin-0, 1000-xmax,\n",
    "                    cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "                mask[np.where(mask > 0.7)] = 1\n",
    "                mask = np.asfortranarray(mask).astype(np.uint8)\n",
    "                mask_counts = (encode(np.asfortranarray(mask))\n",
    "                               ['counts']).decode('utf8')\n",
    "                label = prediction[0]['labels'][ii].item()\n",
    "                score = prediction[0]['scores'][ii].item()\n",
    "\n",
    "                dict = {}\n",
    "                dict['image_id'] = img_id[i]\n",
    "                dict['bbox'] = [box_x+xmin, box_y+ymin, box_width, box_height]\n",
    "                dict['score'] = float(score)\n",
    "                dict['category_id'] = 1\n",
    "                dict['segmentation'] = {\n",
    "                    \"size\": [1000, 1000], 'counts': mask_counts}\n",
    "                answer.append(dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "jsObj = json.dumps(answer, indent=4)\n",
    "with open('answer.json', \"w\") as f:\n",
    "    f.write(jsObj)\n",
    "    f.close()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f23faf4bfe871c203c8bec80520af5927fc7cb1ae3bd834ddf554ee587ad1c05"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
